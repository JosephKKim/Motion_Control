<!doctype html>
<html lang="en">


<!-- === Header Starts === -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>3D Human Action Control in Latent Space of Transformer VAE</title>

  <link href="./assets/bootstrap.min.css" rel="stylesheet">
  <link href="./assets/font.css" rel="stylesheet" type="text/css">
  <link href="./assets/style.css" rel="stylesheet" type="text/css">
</head>
<!-- === Header Ends === -->


<body bgcolor="antiquewhite">


<!-- === Home Section Starts === -->
<div class="section">
  <!-- === Title Starts === -->
  <div class="header">
    <div class="title", style="padding-top: 25pt;">
      3D Human Action Control in Latent Space of Transformer VAE
    </div>
  </div>
  <!-- === Title Ends === -->
  <!-- <div class="author">d
    <a href="https://zhujiapeng.github.io/" target="_blank">Jiapeng Zhu</a><sup>1</sup>,&nbsp;
    <a href="https://dblp.org/pid/20/9594.html" target="_blank">Ruili Feng</a><sup>2,3</sup>,&nbsp;
    <a href="http://shenyujun.github.io/" target="_blank">Yujun Shen</a><sup>4</sup>,&nbsp;
    <a href="https://sites.google.com/site/zhaodeli" target="_blank">Deli Zhao</a><sup>2</sup>,&nbsp;
    <a href="https://cn.linkedin.com/in/zheng-jun-zha-89943115" target="_blank">Zhengjun Zha</a><sup>3</sup>,&nbsp;
    <a href="http://www.cs.columbia.edu/~jrzhou/" target="_blank">Jingren Zhou</a><sup>2</sup>,&nbsp;
    <a href="https://cqf.io/" target="_blank">Qifeng Chen</a><sup>1</sup>

  </div>
  <div class="institution">
    <sup>1</sup>Hong Kong University of Science and Technology &nbsp; &nbsp; &nbsp; &nbsp;
    <sup>2</sup>Alibaba Group
    <br/>
    <sup>3</sup>University of Science and Technology of China &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
    <sup>4</sup>ByteDance Inc.
  </div> -->
  <div class="link">
    <!-- [<a href="https://arxiv.org/pdf/2106.04488.pdf" target="_blank">Paper</a>] -->
    [<a href="https://github.com/JosephKKim/Motion_Control" target="_blank">Code</a>]
    <!-- [<a href="https://www.youtube.com/watch?v=WltRPecDq10" target="_blank">Demo</a>] -->
  </div>
  <div class="teaser">
    <img src="./assets/UESTC.png">
  </div>
</div>
<!-- === Home Section Ends === -->


<!-- === Overview Section Starts === -->
<div class="section">
  <div class="title">Overview</div>
  <div class="body">
    Action-conditioned transformer VAE has shown its ability to generate realistic and diverse human motion sequences. 
    Taking a step further, we want to control the specific body part of the generated human motions, thereby achieving more degrees of freedom and diversity in human actions. 
    In order to attain the control of the body part, we acquire attribute vectors through low-rank factorization and null space projection. 
    However, we empirically found that the attribute vector of each part is tangled with each other due to the posterior collapse, which is a phenomenon that VAE models are found to ignore the latent variables, especially when using flexible generators. 
    We mitigate this problem using scheduling schemes for KL-term(&beta;) among various attempts to address the posterior collapse. Furthermore, to enhance the controllability, we propose the data augmentation which encourages the change rate of motions to be diverse. 
    We evaluate our approach to UESTC and HumanAct12 datasets in the class conditional settings. We also show that manipulated actions using our method are plausible and human-like. 
    In addition, we show that we can apply our control on the actions, generated in the unconditional settings, which reveals potential for the future research. 
    To the best of our knowledge, our work is the first for directly controlling motions in the latent space without using any other modalities.
  </div>

  <div class="body",
  style="border: 4px solid rgb(14, 14, 74); padding: 10px;">
      <h3> Motivation for the work</h3>
      Manually changing pose parameters (&theta;) lead to problems such as going beyond the normal range of human motion 
      or penetration. 
      The videos below show different effects (sideeffects) when same modification is applied to various classes (class0, class22, class5).


      <hr>
      [Class 0] For class 0 it seems like moving more dynamically, but nothing has changed or showing unnatural behavior. <br>
      [Class 22] For class 22 you can see that the person in moving its arm beyond the normal range of an arm. <br>
      [Class 5] You can see the penetration of hand and stomach in the modified version. Since SMPL model does not consider the penetration, and is just a mesh-based model, penetration is often observed after the modification. 
      <br>
      <br>
      <p style="text-align:center;"><img src="./assets/class0_ss.gif" alt = "unconditional result 1", width="80%", height="50%"></p>
      <p style="margin-top: 10pt; text-align:center; font-size:20px">Class 0: Normal motion after modification<p>
      
      <p style="text-align:center;"><img src="./assets/class22_ss.gif" alt = "unconditional result 2", width="80%"></p>
      <p style="margin-top: 10pt; text-align:center; font-size:20px">Class 22: Out of normal range of human motion<p></p>
      <p style="text-align:center;"><img src="./assets/class5_ss.gif" alt = "unconditional result 2", width="80%" ></p>
      <p style="margin-top: 10pt; text-align:center; font-size:20px">Class 5: Penetration of human body parts<p></p>

    <!-- <p style="margin-top: 10pt; text-align:center; font-size:20px">Full Demo Video<p> -->
</div>
<!-- === Overview Section Ends === -->


<!-- === Result Section Starts === -->
<div class="section">
<div class="title">Results</div>
    <h3> Conditional Results</h3>
    In conditional setting, we can perform part-wise control. Below, we show arm and leg control repectively.
    <p style="margin-top: 10pt; text-align:center; font-size:20px"> Arm <p>
    <table width="100%" style="margin: 0pt auto; text-align: center; border-collapse: separate; border-spacing: 5pt;">
      <tr>
        <td><b>Arm pulled up</b></td>
        <td><b>Original z</b></td>
        <td><b>Arm pulled down</b></td>
      </tr>
      <tr>
        <td><img src="./assets/minus_page_arm.gif" width="90%"></img></td>
        <td><img src="./assets/zero_page_arm.gif" width="90%"></img></td>
        <td><img src="./assets/plus_page_arm.gif" width="90%"></img></td>
      </tr>
    </table>
    In the given class shown above, we can see that the leftmost SMPL model is raising its arm more than that in the middle(Original z). Likewise, when we move latent z to the 
    opposite direction where it makes model to raise its arm, we can see that the right most figure is merely raising its arm. 
    <br>
    <br>
    We can also see that body parts other than arm is identical in those 3 figures.

    <p style="margin-top: 10pt; text-align:center; font-size:20px"> Leg<p>
    <table width="100%" style="margin: 0pt auto; text-align: center; border-collapse: separate; border-spacing: 5pt;">
      <tr>
        <td><b>Leg spread</b></td>
        <td><b>Original z</b></td>
        <td><b>Leg narrowed</b></td>
        
      </tr>
      <tr>
        <td><img src="./assets/minus_page_leg.gif" width="90%"></img></td>
        <td><img src="./assets/zero_page_leg.gif" width="90%"></img></td>
        <td><img src="./assets/plus_page_leg.gif" width="90%"></img></td>
        
      </tr>
    </table>
    In the figures above, when we compare left and right figures with the middle figure(Original z), we can see that angle between legs is changing. Left figure shows the result when moved the
    latent into the leg widening direction. Right figure shows the result when we move to the opposite direction where it narrows the leg of the SMPL model.
    <br>
    <br>
    Please notice that parts other than leg is identical in the 3 figures above.

    <div class="body">
      <h3> Unconditional Results</h3>
      In unconditional setting, we can interpolate between two different class to make new class which is not contained in the train dataset. Further, we can also control the genereted new class using the found direction from our method.
      We show the results below. <br>
      <br>
      <p style="text-align:center;"><img src="./assets/uncond.gif" alt = "unconditional result 1", width="90%"></p>
      <p style="text-align:center;"><img src="./assets/uncond2.gif" alt = "unconditional result 2", width="90%"></p>
     


    <p style="margin-top: 10pt; text-align:center; font-size:20px">Full Demo Video<p>
    

    <div class="body"
    style="border: 4px solid rgb(14, 14, 74); padding: 10px;">
      
      <h3> Application of our method on related work [1]</h3>
      We we could apply our part-wise
      controlling method to other motion generation network[1] to examine the effectiveness our method. 
      <hr>
      (Top) We controlled only arm while leaving rest of the body parts almost unchanged. You can see in the picture on the right that person(rig) is raising its arm more than the original image(left).
      <hr>
      (Bottom) We controlled only leg while leaing the rest of the body parts almost unchanged. You can see in the picture on the right that person(rig) is stretching its leg less than the original image(left).
      

      <br>
      <br>
      <p style="text-align:center;"><img src="./assets/arm_ODMO.gif" alt = "unconditional result 1", width="90%"></p>
      <p style="margin-top: 10pt; text-align:center; font-size:20px">Controlling Arm (raise arm more)<p>
      <p style="text-align:center;"><img src="./assets/leg_ODMO.gif" alt = "unconditional result 2", width="90%"></p>
      <p style="margin-top: 10pt; text-align:center; font-size:20px">Controlling Leg (stretch legs less)<p>
        <hr>
        [1] Lu, Q., Zhang, Y., Lu, M., & Roychowdhury, V. (2022, October). Action-conditioned On-demand Motion Generation. In Proceedings of the 30th ACM International Conference on Multimedia (pp. 2249-2257).
  
  
   

      


    

    <!-- Adjust the frame size based on the demo (Every project differs). -->
    <!-- <div style="position: relative; padding-top: 50%; margin: 20pt auto; text-align: center;">
      <iframe src="https://www.youtube.com/embed/WltRPecDq10" frameborder=0
              style="position: absolute; top: 2.5%; left: 2.5%; width: 95%; height: 100%;"
              allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
              allowfullscreen></iframe>
    </div> -->
  </div>
</div> 
<!-- === Result Section Ends === -->


<!-- === Reference Section Starts === -->
<div class="section">
  <!-- <div class="bibtex">BibTeX</div>
<pre>
  @inproceedings{zhu2021lowrankgan,
    title     = {Low-Rank Subspaces in {GAN}s},
    author    = {Zhu, Jiapeng and Feng, Ruili and Shen, Yujun and Zhao, Deli and Zha, Zhengjun and Zhou, Jingren and Chen, Qifeng},
    booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
    year      = {2021}
  }

</pre> -->
<div class="ref">Related Work</div>
<div class="citation">
  <div class="image"><img src="./assets/teaser_dep.jpg"></div>
  <div class="comment">
    <a href="https://arxiv.org/pdf/2106.04488.pdf" target="_blank">
      Jiapeng Zhu, Ruili Feng, Yujun Shen, Deli Zhao, Zhengjun Zha, Jingren Zhou, Qifeng Chen <br>
      Low-Rank Subspaces in GANs. <br>
      Conference on Neural Information Processing Systems (NeurIPS) 2021.</a><br>
    <b>Comment:</b>
    Controlling images in latetent space only modifiying the region of interest, while maintaining the rest region.
    <br>
    We also borrowed project page format from the authors of this paper (Thanks!).
  </div>
</div>

<div class="citation">
  <div class="image"><img src="./assets/ACTOR_teaser.png"></div>
  <div class="comment">
    <a href="https://mathis.petrovich.fr/actor/" target="_blank">
      Mathis Petrovich Michael J. Black, and G&uuml;l Varol <br>
      Action-Conditioned 3D Human Motion Synthesis with Transformer VAE. <br>
      ICCV 2021.</a><br>
    <b>Comment:</b>
    Generates action-conditioned realistic and diverse human motion sequences using Transformer-based VAE architecture
  </div>
</div>

</body>
</html>
