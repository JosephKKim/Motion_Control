activation: gelu
archiname: transformer
batch_size: 20
beta_cycle: true
beta_cycle_n: 4
beta_cycle_ratio: 0.5
beta_max: 2.0e-06
beta_sigmoid: false
beta_sigmoid_bias: 13.5
beta_sigmoid_weight: -5.0e-05
cuda: true
dataset: humanact12
debug: false
expname: exps
folder: debug/humanact12
glob: true
glob_rot:
- 3.141592653589793
- 0
- 0
jointstype: vertices
lambda_kl: cycle
lambda_rc: 1.0
lambda_rcxyz: 1.0
lambdas:
  kl: cycle
  rc: 1.0
  rcxyz: 1.0
latent_dim: 256
losses:
- rc
- rcxyz
- kl
lr: 0.0001
max_len: -1
min_len: -1
modelname: cvae_transformer_rc_rcxyz_kl
modeltype: cvae
num_epochs: 5000
num_frames: 60
num_layers: 8
num_seq_max: -1
pose_rep: rot6d
sampling: conseq
sampling_step: 1
snapshot: 100
translation: true
vertstrans: false
